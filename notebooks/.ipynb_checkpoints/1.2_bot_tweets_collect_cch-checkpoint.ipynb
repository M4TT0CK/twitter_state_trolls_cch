{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# TROLL HUNTING: DETECTING STATE-BACKED DISINFORMATION CAMPAIGNS ON TWITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEOOK 1.2: HARVESTING FAKE TWEETS BY RUSSIAN STATE OPERATORS\n",
    "Here, I'll harvest several sets of tweets from the main corpus of Russian state-backed tweets, as identified and released by Twitter in October 2018.\n",
    "\n",
    "The CSV file with tweets by Russia's infamous Internet Research Agency is about 5.4Gb, and I've not included it in this repo due to the file size. You can download it [here](https://about.twitter.com/en_us/values/elections-integrity.html#data)\n",
    "\n",
    "If you are re-running this file, do note that it would take a long time to run as I'm filtering out the non-English tweets, as well as users who described their location in Russian or other languages.\n",
    "\n",
    "While the use of foreign languages is defintely one of the traits of these state-backed twitter accounts, including these tweets in the dataset would hurt the model's accuracy as it would simply classify any non-English tweets as likely state-tweets.\n",
    "\n",
    "I'm also filtering out retweets by these state-backed accounts, as they don't reflect actual writing by the operators handling the accounts. Clearly, RTs are a feature of state-bot account behaviour. \n",
    "\n",
    "But like the language issue, including RTs would likely skew the model's predictions as the retweets are in fairly high number. RTs are also likely to muddle the countvectorizer's results.\n",
    "\n",
    "A more complex project investigating this subject would find a way to address the language and RT issues. \n",
    "\n",
    "#### But in the context of my project, I'll limit the analysis and predictions to English-language tweets that are non-retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langdetect import detect\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# REPEAT: This CSV file is not included in this repo due to the huge file size. Download using link above\n",
    "fake = pd.read_csv('../data/ira_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The large sample size used here is due to the large number of RTs and non-English tweets in the original dataset\n",
    "# Reducing the sample size here would likely get you less than the required 50K tweets.\n",
    "fake_tweets = fake.sample(n=850000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping these columns for consistency with the real tweets dataset\n",
    "fake_tweets = fake_tweets.drop(\n",
    "    columns=[\n",
    "        \"userid\",\n",
    "        \"user_display_name\",\n",
    "        \"user_profile_url\",\n",
    "        \"tweet_client_name\",\n",
    "        \"in_reply_to_tweetid\",\n",
    "        \"in_reply_to_userid\",\n",
    "        \"quoted_tweet_tweetid\",\n",
    "        \"is_retweet\",\n",
    "        \"retweet_userid\",\n",
    "        \"retweet_tweetid\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"quote_count\",\n",
    "        \"reply_count\",\n",
    "        \"like_count\",\n",
    "        \"retweet_count\",\n",
    "        \"urls\",\n",
    "        \"user_mentions\",\n",
    "        \"poll_choices\",\n",
    "        \"hashtags\",\n",
    "        \"account_language\",\n",
    "        \"tweet_language\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm writing two functions to filter out non-English tweets. \n",
    "# In earlier tests, one filter alone was not enough to catch all the Russian-language tweets\n",
    "def detect_language_langdetect(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_textblob(text):\n",
    "    try:\n",
    "        return TextBlob(text).detect_language\n",
    "    except:\n",
    "        return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweets['lang_textblob'] = fake_tweets['tweet_text'].apply(detect_language_textblob)\n",
    "fake_tweets['lang_textblob_loc'] = fake_tweets['user_reported_location'].apply(detect_language_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweets['langdetect'] = fake_tweets['tweet_text'].apply(detect_language_langdetect)\n",
    "fake_tweets['langdetect_loc'] = fake_tweets['user_reported_location'].apply(detect_language_langdetect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweets = fake_tweets[(fake_tweets['langdetect'] == 'en') & (fake_tweets['langdetect_loc'] == 'en')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>lang_textblob</th>\n",
       "      <th>lang_textblob_loc</th>\n",
       "      <th>langdetect</th>\n",
       "      <th>langdetect_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1415203</th>\n",
       "      <td>631482168695353345</td>\n",
       "      <td>NewOrleansON</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Breaking news, weather, traffic and more for N...</td>\n",
       "      <td>35988</td>\n",
       "      <td>11010</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>Former LSU RB Alfred Blue atop Houston Texans'...</td>\n",
       "      <td>2015-08-12 15:07</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911493</th>\n",
       "      <td>825950748055728129</td>\n",
       "      <td>a95a911dd6ae864c48ed062cdbe75e5c28dbe0cf57c6db...</td>\n",
       "      <td>United States</td>\n",
       "      <td>No more #HappyHolidays shit!!! It's #MerryChri...</td>\n",
       "      <td>2748</td>\n",
       "      <td>265</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>RT @GrrrGraphics: #NEWGameinTown #PresidentTru...</td>\n",
       "      <td>2017-01-30 06:16</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288399</th>\n",
       "      <td>855607672103514114</td>\n",
       "      <td>a95a911dd6ae864c48ed062cdbe75e5c28dbe0cf57c6db...</td>\n",
       "      <td>United States</td>\n",
       "      <td>No more #HappyHolidays shit!!! It's #MerryChri...</td>\n",
       "      <td>2748</td>\n",
       "      <td>265</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>RT @charliekirk11: The power of a movement!  #...</td>\n",
       "      <td>2017-04-22 02:22</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265519</th>\n",
       "      <td>639019849369321472</td>\n",
       "      <td>005b6c0f7e3371b1cacced2890fead3d5543694ab21372...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>153</td>\n",
       "      <td>2014-08-05</td>\n",
       "      <td>harapova pulls out of U.S. GOPsen</td>\n",
       "      <td>2015-09-02 10:19</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345699</th>\n",
       "      <td>870918783614935040</td>\n",
       "      <td>a95a911dd6ae864c48ed062cdbe75e5c28dbe0cf57c6db...</td>\n",
       "      <td>United States</td>\n",
       "      <td>No more #HappyHolidays shit!!! It's #MerryChri...</td>\n",
       "      <td>2748</td>\n",
       "      <td>265</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>RT @KamVTV: You see? Liberal limousine celebri...</td>\n",
       "      <td>2017-06-03 08:23</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>&lt;bound method BaseBlob.detect_language of Text...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweetid  \\\n",
       "1415203  631482168695353345   \n",
       "911493   825950748055728129   \n",
       "3288399  855607672103514114   \n",
       "1265519  639019849369321472   \n",
       "345699   870918783614935040   \n",
       "\n",
       "                                          user_screen_name  \\\n",
       "1415203                                       NewOrleansON   \n",
       "911493   a95a911dd6ae864c48ed062cdbe75e5c28dbe0cf57c6db...   \n",
       "3288399  a95a911dd6ae864c48ed062cdbe75e5c28dbe0cf57c6db...   \n",
       "1265519  005b6c0f7e3371b1cacced2890fead3d5543694ab21372...   \n",
       "345699   a95a911dd6ae864c48ed062cdbe75e5c28dbe0cf57c6db...   \n",
       "\n",
       "        user_reported_location  \\\n",
       "1415203        New Orleans, LA   \n",
       "911493           United States   \n",
       "3288399          United States   \n",
       "1265519           New York, NY   \n",
       "345699           United States   \n",
       "\n",
       "                                  user_profile_description  follower_count  \\\n",
       "1415203  Breaking news, weather, traffic and more for N...           35988   \n",
       "911493   No more #HappyHolidays shit!!! It's #MerryChri...            2748   \n",
       "3288399  No more #HappyHolidays shit!!! It's #MerryChri...            2748   \n",
       "1265519                                                NaN             112   \n",
       "345699   No more #HappyHolidays shit!!! It's #MerryChri...            2748   \n",
       "\n",
       "         following_count account_creation_date  \\\n",
       "1415203            11010            2014-05-05   \n",
       "911493               265            2016-06-15   \n",
       "3288399              265            2016-06-15   \n",
       "1265519              153            2014-08-05   \n",
       "345699               265            2016-06-15   \n",
       "\n",
       "                                                tweet_text        tweet_time  \\\n",
       "1415203  Former LSU RB Alfred Blue atop Houston Texans'...  2015-08-12 15:07   \n",
       "911493   RT @GrrrGraphics: #NEWGameinTown #PresidentTru...  2017-01-30 06:16   \n",
       "3288399  RT @charliekirk11: The power of a movement!  #...  2017-04-22 02:22   \n",
       "1265519                  harapova pulls out of U.S. GOPsen  2015-09-02 10:19   \n",
       "345699   RT @KamVTV: You see? Liberal limousine celebri...  2017-06-03 08:23   \n",
       "\n",
       "                                             lang_textblob  \\\n",
       "1415203  <bound method BaseBlob.detect_language of Text...   \n",
       "911493   <bound method BaseBlob.detect_language of Text...   \n",
       "3288399  <bound method BaseBlob.detect_language of Text...   \n",
       "1265519  <bound method BaseBlob.detect_language of Text...   \n",
       "345699   <bound method BaseBlob.detect_language of Text...   \n",
       "\n",
       "                                         lang_textblob_loc langdetect  \\\n",
       "1415203  <bound method BaseBlob.detect_language of Text...         en   \n",
       "911493   <bound method BaseBlob.detect_language of Text...         en   \n",
       "3288399  <bound method BaseBlob.detect_language of Text...         en   \n",
       "1265519  <bound method BaseBlob.detect_language of Text...         en   \n",
       "345699   <bound method BaseBlob.detect_language of Text...         en   \n",
       "\n",
       "        langdetect_loc  \n",
       "1415203             en  \n",
       "911493              en  \n",
       "3288399             en  \n",
       "1265519             en  \n",
       "345699              en  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    93164\n",
       "Name: langdetect, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tweets['langdetect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweets = fake_tweets[~fake_tweets['tweet_text'].str.startswith(\"RT @\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64038, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almost one third of the English-language fake tweets by the IRA in our dataset are RTs\n",
    "# Not removing them would skew our analysis. Likewise, the language detectors also filtered out\n",
    "# some 89% of the tweets in the original sample which contained some Russian language \n",
    "fake_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_50K = fake_tweets[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_50K = fake_50K.drop(columns=['langdetect', 'langdetect_loc', 'lang_textblob', 'lang_textblob_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_50K = fake_50K[\n",
    "    [\n",
    "        \"tweetid\",\n",
    "        \"user_screen_name\",\n",
    "        \"user_reported_location\",\n",
    "        \"user_profile_description\",\n",
    "        \"follower_count\",\n",
    "        \"following_count\",\n",
    "        \"account_creation_date\",\n",
    "        \"tweet_time\",\n",
    "        \"tweet_text\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting a training set of 50K fake tweets\n",
    "# NOTE: This CSV file is included in the repo\n",
    "\n",
    "#fake_sample = fake_50K.to_csv('../data/bot_50k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting an unseen test set of 1K fake tweets\n",
    "# NOTE: This CSV file is also included in the repo\n",
    "\n",
    "#fake_unseen_sample = fake_tweets[:-14046].drop(columns=['langdetect', 'langdetect_loc', 'lang_textblob', 'lang_textblob_loc'])\n",
    "#test_fake = fake_unseen_sample.sample(n=1000, random_state=42)\n",
    "#test_fake = test_fake.to_csv('../data/fake_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
