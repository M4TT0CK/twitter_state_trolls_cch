{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNCOVERING STATE-BACKED TROLLS ON TWITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEOOK 1.3: DATA CLEANING AND FEATURE ENGINEERING\n",
    "Here, I'll clean up and conduct feature engineering on the two training data sets concurrently so that there's consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_csv('../data/real_50k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = pd.read_csv('../data/bot_50k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 9), (50000, 9))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.shape, state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FEATURE ENGINEERING \n",
    "I'll start with feature engineering first, so that the text \"cleaning\" of the tweet_text column won't be affected. I'll extract the following features from each tweet/account:\n",
    "- hashtags\n",
    "- links\n",
    "- upper-case words\n",
    "- number of characters\n",
    "- number of words\n",
    "- average number of words\n",
    "- follower-following ratio\n",
    "- year+month of account creation\n",
    "- year+month+day of tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 EXTRACTING NEW FEATURES FROM THE TWEET_TEXT COL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hastags\n",
    "real['hashtags'] = real['tweet_text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['hashtags'] = state['tweet_text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links\n",
    "real['links'] = real['tweet_text'].apply(lambda x: len([x for x in x.split() if x.startswith('https')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['links'] = state['tweet_text'].apply(lambda x: len([x for x in x.split() if x.startswith('https')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper-case words\n",
    "real['upper'] = real['tweet_text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['upper'] = state['tweet_text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters in each tweet\n",
    "real['char_count'] = real['tweet_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['char_count'] = state['tweet_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words in tweet text\n",
    "real['tweet_word_count'] = real['tweet_text'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['tweet_word_count'] = state['tweet_text'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average word length of each tweet\n",
    "def avg_word(tweet):\n",
    "    words = tweet.split()\n",
    "    return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['average_num_of_words'] = real['tweet_text'].apply(lambda x: avg_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['average_num_of_words'] = state['tweet_text'].apply(lambda x: avg_word(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 FOLLOWER-FOLLOWING RATIO\n",
    "One likely characteristic of state-backed accounts is they follow a lot of users (or fellow fake accounts), and have very few real followers, ie, unusually low follower-to-following ratio (less than 1 perhaps). Let's create a new column to for this ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['follower-to-following_ratio'] = real['follower_count'] / real['following_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686531.888889    539\n",
       "526.306034       505\n",
       "277.798291       393\n",
       "2150.187179      245\n",
       "2456.752212      197\n",
       "Name: follower-to-following_ratio, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['follower-to-following_ratio'].value_counts().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['follower-to-following_ratio'] = state['follower_count'] / state['following_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.142857    1\n",
       "0.196388    1\n",
       "0.687861    1\n",
       "0.186047    1\n",
       "1.963636    1\n",
       "Name: follower-to-following_ratio, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state['follower-to-following_ratio'].value_counts().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 YEAR OF ACCOUNT CREATION\n",
    "We know that a lot of state-backed accounts were created in 2014, and thereafter, following the setup of the Internet Research Agency. So it will be worthwhile to isolate this element for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['account_creation_date'] = pd.to_datetime(real['account_creation_date'], yearfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['account_creation_date'] = pd.to_datetime(state['account_creation_date'], yearfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2014-10-07 19:55:59+00:00\n",
       "1   2009-01-09 04:12:46+00:00\n",
       "2   2009-08-11 07:50:45+00:00\n",
       "3   2008-04-25 17:23:28+00:00\n",
       "4   2009-03-06 03:20:20+00:00\n",
       "Name: account_creation_date, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['account_creation_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['year_of_account_creation'] = real['account_creation_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['year_of_account_creation'] = state['account_creation_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['month_of_account_creation'] = real['account_creation_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['month_of_account_creation'] = state['account_creation_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 TWEET TIME \n",
    "Another key assumption is that the state-backed accounts stepped up their activities closer to the US election. Splitting up the tweet times according to year, month and day will allow us to group these tweets more easily during the visualisation phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['tweet_time'] = pd.to_datetime(real['tweet_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['tweet_time'] = pd.to_datetime(state['tweet_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['tweet_year'] = real['tweet_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['tweet_year'] = state['tweet_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['tweet_month'] = real['tweet_time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['tweet_month'] = state['tweet_time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['tweet_day'] = real['tweet_time'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['tweet_day'] = state['tweet_time'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 CLEAN UP TWEET_TEXT COL\n",
    "I'll keep the original tweet text column for reference, and create a newly cleaned column with punctuation etc taken out for the NLP portion of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(\"\\W\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip(\" \")\n",
    "    text = text.strip(\"\\n\")\n",
    "    text = re.sub(\"[^\\w\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "real['clean_tweet_text'] = real['tweet_text'].map(lambda tweet: clean_tweet(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['clean_tweet_text'] = state['tweet_text'].map(lambda tweet: clean_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHECKING ON NULL VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 22 columns):\n",
      "tweetid                        50000 non-null int64\n",
      "user_screen_name               50000 non-null object\n",
      "user_reported_location         50000 non-null object\n",
      "user_profile_description       50000 non-null object\n",
      "follower_count                 50000 non-null int64\n",
      "following_count                50000 non-null int64\n",
      "account_creation_date          50000 non-null datetime64[ns, UTC]\n",
      "tweet_time                     50000 non-null datetime64[ns]\n",
      "tweet_text                     50000 non-null object\n",
      "hashtags                       50000 non-null int64\n",
      "links                          50000 non-null int64\n",
      "upper                          50000 non-null int64\n",
      "char_count                     50000 non-null int64\n",
      "tweet_word_count               50000 non-null int64\n",
      "average_num_of_words           50000 non-null float64\n",
      "follower-to-following_ratio    50000 non-null float64\n",
      "year_of_account_creation       50000 non-null int64\n",
      "month_of_account_creation      50000 non-null int64\n",
      "tweet_year                     50000 non-null int64\n",
      "tweet_month                    50000 non-null int64\n",
      "tweet_day                      50000 non-null int64\n",
      "clean_tweet_text               50000 non-null object\n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(2), int64(13), object(5)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "real.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DF on real users looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 22 columns):\n",
      "tweetid                        50000 non-null int64\n",
      "user_screen_name               50000 non-null object\n",
      "user_reported_location         50000 non-null object\n",
      "user_profile_description       46935 non-null object\n",
      "follower_count                 50000 non-null int64\n",
      "following_count                50000 non-null int64\n",
      "account_creation_date          50000 non-null datetime64[ns]\n",
      "tweet_time                     50000 non-null datetime64[ns]\n",
      "tweet_text                     50000 non-null object\n",
      "hashtags                       50000 non-null int64\n",
      "links                          50000 non-null int64\n",
      "upper                          50000 non-null int64\n",
      "char_count                     50000 non-null int64\n",
      "tweet_word_count               50000 non-null int64\n",
      "average_num_of_words           50000 non-null float64\n",
      "follower-to-following_ratio    49987 non-null float64\n",
      "year_of_account_creation       50000 non-null int64\n",
      "month_of_account_creation      50000 non-null int64\n",
      "tweet_year                     50000 non-null int64\n",
      "tweet_month                    50000 non-null int64\n",
      "tweet_day                      50000 non-null int64\n",
      "clean_tweet_text               50000 non-null object\n",
      "dtypes: datetime64[ns](2), float64(2), int64(13), object(5)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Some missing values in 3 columns to deal with in the state-operated tweets DF\n",
    "state.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['user_reported_location'] = state['user_reported_location'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['user_profile_description'] = state['user_profile_description'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing numbers here with the median, since max values tend to infinity due to the presence of 0 values\n",
    "state['follower-to-following_ratio'] = state['follower-to-following_ratio'].fillna(1.779081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OUTPUTTING NEW DFS FOR VISUALISATION-MODELLING\n",
    "I'm reasonably happy with number of features and initial cleaning. I'll re-group the columns and output them as new DFs for visualisation and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_full = real[\n",
    "    [\n",
    "        \"tweetid\",\n",
    "        \"user_screen_name\",\n",
    "        \"user_reported_location\",\n",
    "        \"user_profile_description\",\n",
    "        \"follower_count\",\n",
    "        \"following_count\",\n",
    "        \"follower-to-following_ratio\",\n",
    "        \"account_creation_date\",\n",
    "        \"year_of_account_creation\",\n",
    "        \"month_of_account_creation\",\n",
    "        \"tweet_time\",\n",
    "        \"tweet_year\",\n",
    "        \"tweet_month\",\n",
    "        \"tweet_day\",\n",
    "        \"tweet_text\",\n",
    "        \"clean_tweet_text\",\n",
    "        \"hashtags\",\n",
    "        \"links\",\n",
    "        \"upper\",\n",
    "        \"char_count\",\n",
    "        \"tweet_word_count\",\n",
    "        \"average_num_of_words\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_full = state[\n",
    "    [\n",
    "        \"tweetid\",\n",
    "        \"user_screen_name\",\n",
    "        \"user_reported_location\",\n",
    "        \"user_profile_description\",\n",
    "        \"follower_count\",\n",
    "        \"following_count\",\n",
    "        \"follower-to-following_ratio\",\n",
    "        \"account_creation_date\",\n",
    "        \"year_of_account_creation\",\n",
    "        \"month_of_account_creation\",\n",
    "        \"tweet_time\",\n",
    "        \"tweet_year\",\n",
    "        \"tweet_month\",\n",
    "        \"tweet_day\",\n",
    "        \"tweet_text\",\n",
    "        \"clean_tweet_text\",\n",
    "        \"hashtags\",\n",
    "        \"links\",\n",
    "        \"upper\",\n",
    "        \"char_count\",\n",
    "        \"tweet_word_count\",\n",
    "        \"average_num_of_words\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 22), (50000, 22))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_full.shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_full = real_full.to_csv('../data/real.csv', index=False)\n",
    "# NOTE: This CSV is included in the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_full = state_full.to_csv('../data/state.csv', index=False)\n",
    "# NOTE: This CSV is also included in the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'll visualise the data in the nextbook, 2.0.  In notebook 1.4, I'll create the unseen test sets needed to gauge the eventual model's ability to generalise across fake tweets from different countries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
