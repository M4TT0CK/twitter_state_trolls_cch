{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# TROLL HUNTING: DETECTING STATE-BACKED DISINFORMATION CAMPAIGNS ON TWITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEOOK 1.5:\n",
    "I decided to add this notebook after reviewing the initial rounds of results of my Logistic Regression model. More will be explained later, but here I'll create another training set of fake tweets, this time from Iran, to build a model that is trained on Iranian troll tweets (plus real tweets from American verified users). \n",
    "\n",
    "It would be too unwieldly to incorporate this in the earlier notebooks.  \n",
    "\n",
    "The dataset generated here will be used in notebook 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from textblob import TextBlob\n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This CSV is NOT included in this repo due to the file size. \n",
    "# Download via earlier link shared from Twitter's Elections Integrity site\n",
    "iran = pd.read_csv('../data/iranian_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1122936, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm following a similar set of cleaning routines in the earlier notebook for Russian state-backed tweets\n",
    "# I'm focusing only on English tweets as well as non-RTs\n",
    "iran = iran.drop(\n",
    "    columns=[\n",
    "        \"userid\",\n",
    "        \"user_display_name\",\n",
    "        \"user_profile_url\",\n",
    "        \"tweet_client_name\",\n",
    "        \"in_reply_to_tweetid\",\n",
    "        \"in_reply_to_userid\",\n",
    "        \"quoted_tweet_tweetid\",\n",
    "        \"is_retweet\",\n",
    "        \"retweet_userid\",\n",
    "        \"retweet_tweetid\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"quote_count\",\n",
    "        \"reply_count\",\n",
    "        \"like_count\",\n",
    "        \"retweet_count\",\n",
    "        \"urls\",\n",
    "        \"user_mentions\",\n",
    "        \"poll_choices\",\n",
    "        \"hashtags\",\n",
    "        \"account_language\",\n",
    "        \"tweet_language\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets = iran.sample(n=1000000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_langdetect(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_textblob(text):\n",
    "    try:\n",
    "        return TextBlob(text).detect_language\n",
    "    except:\n",
    "        return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets['lang_textblob'] = iran_tweets['tweet_text'].apply(detect_language_textblob)\n",
    "iran_tweets['lang_textblob_loc'] = iran_tweets['user_reported_location'].apply(detect_language_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets['langdetect'] = iran_tweets['tweet_text'].apply(detect_language_langdetect)\n",
    "iran_tweets['langdetect_loc'] = iran_tweets['user_reported_location'].apply(detect_language_langdetect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets = iran_tweets[(iran_tweets['langdetect'] == 'en') & (iran_tweets['langdetect_loc'] == 'en')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    64767\n",
       "Name: langdetect, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iran_tweets['langdetect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets = iran_tweets[~iran_tweets['tweet_text'].str.startswith(\"RT @\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets = iran_tweets.drop(columns=['langdetect', 'langdetect_loc', 'lang_textblob', 'lang_textblob_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets = iran_tweets[\n",
    "    [\n",
    "        \"tweetid\",\n",
    "        \"user_screen_name\",\n",
    "        \"user_reported_location\",\n",
    "        \"user_profile_description\",\n",
    "        \"follower_count\",\n",
    "        \"following_count\",\n",
    "        \"account_creation_date\",\n",
    "        \"tweet_time\",\n",
    "        \"tweet_text\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_tweets = iran_tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37294, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iran_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This CSV is included in the repo\n",
    "#iran_full_en = iran_tweets.to_csv('../data/iran_full_en.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the end of the section on data collection and formatting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
